{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11122238,"sourceType":"datasetVersion","datasetId":6935774},{"sourceId":1497,"sourceType":"modelInstanceVersion","modelInstanceId":1265,"modelId":191}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import relevant libraries \n\nimport re\nimport random\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import plot_model\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import top_k_accuracy_score, classification_report, precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\nfrom sklearn.metrics import confusion_matrix, mean_absolute_error\n#from scikitplot.metrics import plot_roc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:38:58.256306Z","iopub.execute_input":"2025-03-24T02:38:58.256614Z","iopub.status.idle":"2025-03-24T02:39:17.356194Z","shell.execute_reply.started":"2025-03-24T02:38:58.256578Z","shell.execute_reply":"2025-03-24T02:39:17.355373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\n# https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html\n\n#plt.style.use('seaborn-v0_8-colorblind')\n#plt.style.use('default')\n#plt.style.use('seaborn-v0_8-dark-palette')\n#plt.style.use('seaborn-pastel')\nplt.style.use('default')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:39:53.517201Z","iopub.execute_input":"2025-03-24T02:39:53.517540Z","iopub.status.idle":"2025-03-24T02:39:53.523470Z","shell.execute_reply.started":"2025-03-24T02:39:53.517516Z","shell.execute_reply":"2025-03-24T02:39:53.522170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Define configs\n\nclass CFG:\n    SEED = 768\n    BATCH_SIZE = 32\n    EPOCHS = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:39:56.770602Z","iopub.execute_input":"2025-03-24T02:39:56.770951Z","iopub.status.idle":"2025-03-24T02:39:56.775116Z","shell.execute_reply.started":"2025-03-24T02:39:56.770921Z","shell.execute_reply":"2025-03-24T02:39:56.773976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def seed_everything(seed=CFG.SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything(CFG.SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:39:57.367647Z","iopub.execute_input":"2025-03-24T02:39:57.367963Z","iopub.status.idle":"2025-03-24T02:39:57.372812Z","shell.execute_reply.started":"2025-03-24T02:39:57.367940Z","shell.execute_reply":"2025-03-24T02:39:57.371689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define paths\nDATASET_PATH = \"/kaggle/input/nlp-sentiments-analysis\"\nTRAIN_CSV = '/kaggle/input/nlp-sentiments-analysis/train.csv'\nTEST_CSV = '/kaggle/input/nlp-sentiments-analysis/test.csv'\nSAMPLE_SUB_CSV = '/kaggle/input/nlp-sentiments-analysis/sample_submission.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:39:59.658564Z","iopub.execute_input":"2025-03-24T02:39:59.658883Z","iopub.status.idle":"2025-03-24T02:39:59.663291Z","shell.execute_reply.started":"2025-03-24T02:39:59.658853Z","shell.execute_reply":"2025-03-24T02:39:59.662069Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset Exploration","metadata":{}},{"cell_type":"code","source":"# Load the csv files\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\nsubmission_df = pd.read_csv(SAMPLE_SUB_CSV) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:01.929356Z","iopub.execute_input":"2025-03-24T02:40:01.929705Z","iopub.status.idle":"2025-03-24T02:40:02.936607Z","shell.execute_reply.started":"2025-03-24T02:40:01.929679Z","shell.execute_reply":"2025-03-24T02:40:02.935569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:04.281801Z","iopub.execute_input":"2025-03-24T02:40:04.282153Z","iopub.status.idle":"2025-03-24T02:40:04.325585Z","shell.execute_reply.started":"2025-03-24T02:40:04.282127Z","shell.execute_reply":"2025-03-24T02:40:04.324623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:06.428702Z","iopub.execute_input":"2025-03-24T02:40:06.429008Z","iopub.status.idle":"2025-03-24T02:40:06.450780Z","shell.execute_reply.started":"2025-03-24T02:40:06.428985Z","shell.execute_reply":"2025-03-24T02:40:06.449835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# view random selected data\n\ndef view_samples(df, count=5):\n    idx = random.sample(train_df.index.to_list(), count)\n    print('=========================================\\n')\n    for _ in idx:\n        print(f'id:\\t{df.Id[_]}\\n')\n        print(f'Review:\\n{df.Review[_]}\\n')\n        print(f'Rating:\\n{df.Rating[_]}')\n        print('=========================================\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:08.379407Z","iopub.execute_input":"2025-03-24T02:40:08.379731Z","iopub.status.idle":"2025-03-24T02:40:08.384686Z","shell.execute_reply.started":"2025-03-24T02:40:08.379706Z","shell.execute_reply":"2025-03-24T02:40:08.383762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# view randomly selected data\n\nview_samples(train_df, count=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:10.127742Z","iopub.execute_input":"2025-03-24T02:40:10.128127Z","iopub.status.idle":"2025-03-24T02:40:10.140683Z","shell.execute_reply.started":"2025-03-24T02:40:10.128088Z","shell.execute_reply":"2025-03-24T02:40:10.139653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_distribution = train_df['Rating'].value_counts().sort_values()\ntrain_distribution","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:13.428915Z","iopub.execute_input":"2025-03-24T02:40:13.429452Z","iopub.status.idle":"2025-03-24T02:40:13.439429Z","shell.execute_reply.started":"2025-03-24T02:40:13.429417Z","shell.execute_reply":"2025-03-24T02:40:13.438432Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# View Train Rating Distribution\nplt.figure(figsize=(15, 8))\nplt.title('Train Rating Distribution', fontsize=20)\n\ntrain_distribution = train_df['Rating'].value_counts().sort_values()\nsns.barplot(x=list(train_distribution.keys()),\n            y=train_distribution.values);\n\nsns.despine();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:14.168789Z","iopub.execute_input":"2025-03-24T02:40:14.169188Z","iopub.status.idle":"2025-03-24T02:40:14.501312Z","shell.execute_reply.started":"2025-03-24T02:40:14.169158Z","shell.execute_reply":"2025-03-24T02:40:14.499874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the lengths of each review\ntrain_df['review_length'] = [len(_) for _ in train_df.Review]\n\n# Get the number of tokens per review \ntrain_df['token_count'] = [len(_.split()) for _ in train_df.Review]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:18.269171Z","iopub.execute_input":"2025-03-24T02:40:18.269525Z","iopub.status.idle":"2025-03-24T02:40:18.574696Z","shell.execute_reply.started":"2025-03-24T02:40:18.269496Z","shell.execute_reply":"2025-03-24T02:40:18.573673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:18.761741Z","iopub.execute_input":"2025-03-24T02:40:18.762152Z","iopub.status.idle":"2025-03-24T02:40:18.771555Z","shell.execute_reply.started":"2025-03-24T02:40:18.762121Z","shell.execute_reply":"2025-03-24T02:40:18.770455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"{train_df['review_length'].describe()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:19.484163Z","iopub.execute_input":"2025-03-24T02:40:19.484469Z","iopub.status.idle":"2025-03-24T02:40:19.495987Z","shell.execute_reply.started":"2025-03-24T02:40:19.484447Z","shell.execute_reply":"2025-03-24T02:40:19.495009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"{train_df['token_count'].describe()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:21.999737Z","iopub.execute_input":"2025-03-24T02:40:22.000205Z","iopub.status.idle":"2025-03-24T02:40:22.010965Z","shell.execute_reply.started":"2025-03-24T02:40:22.000174Z","shell.execute_reply":"2025-03-24T02:40:22.009762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Review lengths of Ratings\n\nfig, (ax1, ax2) = plt.subplots(2, figsize=(14, 18))\n\n# Set the spacing between subplots\nfig.tight_layout(pad=6.0)\n\n# Plot Range of Review Lengths per Rating\nax1.set_title('Review Lengths per Rating', fontsize=20)\nsns.boxplot(data=train_df, y='review_length', x='Rating',\n            ax=ax1)\nax1.set_xlabel('Rating', fontsize=14)\nax1.set_ylabel('review_length', fontsize=14)\nsns.despine();\n\n# Plot Range of Token Counts per Rating\nax2.set_title('Token Counts per Rating', fontsize=20)\nsns.boxplot(data=train_df, y='token_count', x='Rating',\n            ax=ax2);\nax2.set_xlabel('Rating', fontsize=14)\nax2.set_ylabel('token_count', fontsize=14)\nsns.despine();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:23.948616Z","iopub.execute_input":"2025-03-24T02:40:23.949007Z","iopub.status.idle":"2025-03-24T02:40:24.651860Z","shell.execute_reply.started":"2025-03-24T02:40:23.948976Z","shell.execute_reply":"2025-03-24T02:40:24.650839Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, figsize=(14, 10))\n\n# Set the spacing between subplots\nfig.tight_layout(pad=6.0)\n\n# Generate Train Rating Histogram\nax1.set_title('Train Review Length Histogram', fontsize=20)\nsns.histplot(data=train_df, x='review_length', bins=50,\n            ax=ax1)\nax1.set_xlabel('review_length', fontsize=14)\nax1.set_ylabel('Count', fontsize=14)\nsns.despine();\n\n# Generate Train Token Count Histogram\nax2.set_title('Train Token Count Histogram', fontsize=20)\nsns.histplot(data=train_df, x='token_count', bins=50,\n            ax=ax2)\nax2.set_xlabel('token_count', fontsize=14)\nax2.set_ylabel('Count', fontsize=14)\nsns.despine();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:42.233107Z","iopub.execute_input":"2025-03-24T02:40:42.233552Z","iopub.status.idle":"2025-03-24T02:40:42.957465Z","shell.execute_reply.started":"2025-03-24T02:40:42.233515Z","shell.execute_reply":"2025-03-24T02:40:42.956305Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Label encode ratings\ntrain_df[\"rating_encoded\"] = train_df['Rating'] - 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:45.979177Z","iopub.execute_input":"2025-03-24T02:40:45.979541Z","iopub.status.idle":"2025-03-24T02:40:45.985239Z","shell.execute_reply.started":"2025-03-24T02:40:45.979512Z","shell.execute_reply":"2025-03-24T02:40:45.984098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:55.959844Z","iopub.execute_input":"2025-03-24T02:40:55.960253Z","iopub.status.idle":"2025-03-24T02:40:55.969971Z","shell.execute_reply.started":"2025-03-24T02:40:55.960225Z","shell.execute_reply":"2025-03-24T02:40:55.968993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# get indices of training and test data sets. \ntrain_idx, val_idx, _, _ = train_test_split(\n    train_df.index, train_df.Rating, \n    test_size=0.2, stratify=train_df.Rating,\n    random_state=CFG.SEED\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:56.510330Z","iopub.execute_input":"2025-03-24T02:40:56.510649Z","iopub.status.idle":"2025-03-24T02:40:56.539349Z","shell.execute_reply.started":"2025-03-24T02:40:56.510626Z","shell.execute_reply":"2025-03-24T02:40:56.538546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:40:59.568154Z","iopub.execute_input":"2025-03-24T02:40:59.568486Z","iopub.status.idle":"2025-03-24T02:40:59.574795Z","shell.execute_reply.started":"2025-03-24T02:40:59.568461Z","shell.execute_reply":"2025-03-24T02:40:59.573650Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_new_df = train_df.iloc[train_idx].reset_index(drop= True)\nval_df = train_df.iloc[val_idx].reset_index(drop = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:41:00.078766Z","iopub.execute_input":"2025-03-24T02:41:00.079129Z","iopub.status.idle":"2025-03-24T02:41:00.101940Z","shell.execute_reply.started":"2025-03-24T02:41:00.079104Z","shell.execute_reply":"2025-03-24T02:41:00.100666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_new_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:41:00.802540Z","iopub.execute_input":"2025-03-24T02:41:00.802901Z","iopub.status.idle":"2025-03-24T02:41:00.814727Z","shell.execute_reply.started":"2025-03-24T02:41:00.802871Z","shell.execute_reply":"2025-03-24T02:41:00.813594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train and Test Rating Distribution \nfig, (ax1, ax2) = plt.subplots(2, figsize=(14, 10))\n\n# Set the spacing between subplots\nfig.tight_layout(pad=6.0)\n\n# Plot New Train Ratings Distribution\nax1.set_title('New Train Ratings Distribution', fontsize=20)\ntrain_new_distribution = train_new_df['Rating'].value_counts().sort_values()\nsns.barplot(x=train_new_distribution.values,\n            y=list(train_new_distribution.keys()),\n            orient=\"h\",\n            ax=ax1)\nsns.despine();\n\n# Plot Validation Ratings Distribution\nax2.set_title('Validation Ratings Distribution', fontsize=20)\nval_distribution = val_df['Rating'].value_counts().sort_values()\nsns.barplot(x=val_distribution.values,\n            y=list(val_distribution.keys()),\n            orient=\"h\",\n            ax=ax2);\nsns.despine();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:41:03.200957Z","iopub.execute_input":"2025-03-24T02:41:03.201374Z","iopub.status.idle":"2025-03-24T02:41:03.650608Z","shell.execute_reply.started":"2025-03-24T02:41:03.201345Z","shell.execute_reply":"2025-03-24T02:41:03.649503Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Build Input Data Pipeline with tf.data API","metadata":{}},{"cell_type":"markdown","source":"we'll use the tf.data API to build input data pipelines for training a model and conducting model inference. In order to achieve this, we'll preprocess the reviews by removing any artifacts in the texts such as emojis, non-ascii characters and replacing numbers with another character. The preprocessed texts will be used to construct the pipelines along with the one-hot encoded ratings.","metadata":{}},{"cell_type":"markdown","source":"For more information on the tf.data API and loading data from generator, follow these links:\n\n\n* tf.data: Build TensorFlow input pipelines - https://www.tensorflow.org/guide/data\n* Better performance with the tf.data API - https://www.tensorflow.org/guide/data_performance\n* Using generators with tf.data API -https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Define Text Preprocessor","metadata":{}},{"cell_type":"code","source":"def text_preprocessor(text):\n    \n    # -----------------------------------------------------\n    # Source: https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n    emoji_pattern = re.compile(\"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           \"]+\", flags=re.UNICODE)\n    # -----------------------------------------------------\n    non_ascii_pattern = re.compile(r\"[^\\x00-\\x7F]+\", flags=re.UNICODE)\n    digit_pattern = re.compile('[0-9]', flags=re.UNICODE)\n    \n    # -----------------------------------------------------\n    # Source: https://stackoverflow.com/questions/21932615/regular-expression-for-remove-link\n    link_pattern = re.compile('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)', flags=re.UNICODE)\n    # -----------------------------------------------------\n    \n    # Remove emojis\n    preprocessed_text = emoji_pattern.sub(r'', text)\n    # Remove non-ascii characters\n    preprocessed_text = non_ascii_pattern.sub(r'', preprocessed_text)\n    # Replace numbers with '#' sign\n    preprocessed_text = digit_pattern.sub(r'#', preprocessed_text)\n    # Remove web links \n    preprocessed_text = link_pattern.sub(r'', preprocessed_text)\n    \n    return preprocessed_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:53:03.808514Z","iopub.execute_input":"2025-03-24T02:53:03.808861Z","iopub.status.idle":"2025-03-24T02:53:03.814990Z","shell.execute_reply.started":"2025-03-24T02:53:03.808826Z","shell.execute_reply":"2025-03-24T02:53:03.813723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate Input Data pipelines\n\ndef encode_labels(labels, label_depth=5):\n    return tf.one_hot(labels, depth=label_depth).numpy()\n\ndef create_pipeline(df, preprocessor, batch_size=32, shuffle=False, cache=None, prefetch=False):\n    '''\n    Generates an input pipeline using the tf.data API given a Pandas DataFrame and image loading function.\n    \n    @params\n        - df: (pd.DataFrame) -> DataFrame containing texts and labels\n        - preprocessor (function) -> preprocessor used to preprocess texts\n        - batch_size: (int) -> size for batched (default=32) \n        - shuffle: (bool) -> condition for data shuffling, data is shuffled when True (default=False)\n        - cache: (str) -> cache path for caching data, data is not cached when None (default=None)\n        - prefetch: (bool) -> condition for prefeching data, data is prefetched when True (default=False)\n        \n    @returns\n        - dataset: (tf.data.Dataset) -> dataset input pipeline used to train a TensorFlow model\n    '''\n    # Get image paths and labels from DataFrame\n    reviews = df['Review'].apply(preprocessor).to_numpy().astype(str)\n    ratings = encode_labels(df['rating_encoded'].to_numpy().astype(np.float32))\n    AUTOTUNE = tf.data.AUTOTUNE\n    \n    # Create dataset with raw data from DataFrame\n    ds = tf.data.Dataset.from_tensor_slices((reviews, ratings))\n    \n    # Apply shuffling based on condition\n    if shuffle:\n        ds = ds.shuffle(buffer_size=1000)\n        \n    # Apply batching\n    ds = ds.batch(batch_size)\n    \n    # Apply caching based on condition\n    # Note: Use cache in memory (cache='') if the data is small enough to fit in memory!!!\n    if cache != None:\n        ds = ds.cache(cache)\n    \n    # Apply prefetching based on condition\n    # Note: This will result in memory trade-offs\n    if prefetch:\n        ds = ds.prefetch(buffer_size=AUTOTUNE)\n    \n    # Return the dataset\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:53:05.724722Z","iopub.execute_input":"2025-03-24T02:53:05.725138Z","iopub.status.idle":"2025-03-24T02:53:05.731863Z","shell.execute_reply.started":"2025-03-24T02:53:05.725101Z","shell.execute_reply":"2025-03-24T02:53:05.730843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create train input data pipeline\ntrain_ds = create_pipeline(\n    train_new_df, text_preprocessor, \n    batch_size=CFG.BATCH_SIZE, \n    shuffle=False, prefetch=True\n)\n\n# Create validation input data pipeline\nval_ds = create_pipeline(\n    val_df, text_preprocessor,\n    batch_size=CFG.BATCH_SIZE, \n    shuffle=False, prefetch=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:53:07.552593Z","iopub.execute_input":"2025-03-24T02:53:07.552955Z","iopub.status.idle":"2025-03-24T02:53:15.627141Z","shell.execute_reply.started":"2025-03-24T02:53:07.552925Z","shell.execute_reply":"2025-03-24T02:53:15.626198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# View string representation of datasets\nprint('========================================')\nprint('Train Input Data Pipeline:\\n\\n', train_ds)\nprint('========================================')\nprint('Validation Input Data Pipeline:\\n\\n', val_ds)\nprint('========================================')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:53:15.628551Z","iopub.execute_input":"2025-03-24T02:53:15.628995Z","iopub.status.idle":"2025-03-24T02:53:15.636315Z","shell.execute_reply.started":"2025-03-24T02:53:15.628955Z","shell.execute_reply":"2025-03-24T02:53:15.635341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Baseline Model : Universal Sentence Encoder Model","metadata":{}},{"cell_type":"code","source":"# Here's a function to get any model/preprocessor from tensorflow hub\ndef get_tfhub_model(model_link, model_name, model_trainable=False):\n    return hub.KerasLayer(model_link,\n                          trainable=model_trainable,\n                          name=model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:53:15.638305Z","iopub.execute_input":"2025-03-24T02:53:15.638615Z","iopub.status.idle":"2025-03-24T02:53:15.651440Z","shell.execute_reply.started":"2025-03-24T02:53:15.638590Z","shell.execute_reply":"2025-03-24T02:53:15.650406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Get Universal Sentence Encoder","metadata":{}},{"cell_type":"code","source":"# Get Universal Sentence Encoder here\n# -----------------------------------\n# Note: We'll use the version from Kaggle's Models page instead.\n#       Check it out here: \n#       (https://www.kaggle.com/models/google/universal-sentence-encoder)\n# -----------------------------------\nencoder_link = 'https://kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2'\n# encoder_link = 'https://tfhub.dev/google/universal-sentence-encoder/4'\n\nencoder_name = 'universal_sentence_encoder'\nencoder_trainable=False # set trainable to False for inference-only \n\nencoder = get_tfhub_model(encoder_link, encoder_name, model_trainable=encoder_trainable)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:53:15.652551Z","iopub.execute_input":"2025-03-24T02:53:15.652847Z","iopub.status.idle":"2025-03-24T02:53:22.203660Z","shell.execute_reply.started":"2025-03-24T02:53:15.652824Z","shell.execute_reply":"2025-03-24T02:53:22.202711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Build Model","metadata":{}},{"cell_type":"code","source":"def build_baseline_model(num_classes=5):\n    # Define kernel initializer & input layer\n    initializer = tf.keras.initializers.HeNormal(seed=CFG.SEED)\n    review_input = layers.Input(shape=[], dtype=tf.string, name='review_text_input')\n    \n    # Generate Embeddings\n    review_embedding = encoder(review_input)\n    \n    # Feed Embeddings to a Bidirectional LSTM\n    expand_layer = layers.Lambda(lambda embed: tf.expand_dims(embed, axis=1))(review_embedding)\n    bi_lstm = layers.Bidirectional(layers.LSTM(128, kernel_initializer=initializer), \n                                   name='bidirection_lstm')(expand_layer)\n    \n    # Feed LSTM output to classification head\n    dropout_layer = layers.Dropout(0.25)(bi_lstm)\n    dense_layer = layers.Dense(64, activation='relu', kernel_initializer=initializer)(dropout_layer)\n    output_layer = layers.Dense(num_classes, activation='softmax', \n                                kernel_initializer=initializer, \n                                name='output_layer')(dense_layer)\n    \n    return tf.keras.Model(inputs=[review_input], \n                          outputs=[output_layer], \n                          name='use_model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:44:21.342743Z","iopub.execute_input":"2025-03-24T02:44:21.343008Z","iopub.status.idle":"2025-03-24T02:44:21.349453Z","shell.execute_reply.started":"2025-03-24T02:44:21.342986Z","shell.execute_reply":"2025-03-24T02:44:21.348388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build model\nmodel = build_baseline_model()\n\n# View summary of model\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:44:21.350948Z","iopub.execute_input":"2025-03-24T02:44:21.351329Z","iopub.status.idle":"2025-03-24T02:44:21.401043Z","shell.execute_reply.started":"2025-03-24T02:44:21.351304Z","shell.execute_reply":"2025-03-24T02:44:21.399678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\n\n# Load the Universal Sentence Encoder\nembed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n\n# Ensure input is a list of strings\nsentences = [\"This is a test sentence.\", \"Another example sentence.\"]\nembeddings = embed(sentences)  # Correct input format\n\nprint(embeddings.shape)  # Should output: (2, 512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T02:48:46.821711Z","iopub.execute_input":"2025-03-24T02:48:46.822136Z","iopub.status.idle":"2025-03-24T02:48:53.413087Z","shell.execute_reply.started":"2025-03-24T02:48:46.822081Z","shell.execute_reply":"2025-03-24T02:48:53.411974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}